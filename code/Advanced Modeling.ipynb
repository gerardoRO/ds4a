{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures, OneHotEncoder\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor, LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of continuous features: 6\n",
      "number of categorical features: 12\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/Gerardo/Documents/Projects/ds4a/datasets/current_final_datset.csv')\n",
    "\n",
    "cols_to_scale = ['Community_Spending','Unexpected_Housing_Spending','Govt_Direct_Expenditure','MedianIncome','Number_Interest_Groups','Property_Rights']\n",
    "cols_to_onehot = ['No_Discrimination_Laws','Private_Fair_Housing',\n",
    "                  'Public_Fair_Housing','Urban_Fair_Housing',\n",
    "                  'Banned_Discrimination_Public_Housing',\n",
    "                  'Banned_Discrimination_Private_Housing',\n",
    "                  'Legislation_Public_Housing','Rent_Control',\n",
    "                  'State_Aid_Allowed','Federal_Aid_Allowed',\n",
    "                  'Prohibit_Rent_Control','Metro']\n",
    "possible_labels = ['FMR0','Rent50','MedianIncome','FMRRentPercentInc','Rent50PercInc',\n",
    "                   'Income_Adjusted_FMR0','Income_Adjusted_Rent50','Income_Adjusted_HousingPrices',\n",
    "                   'Affordability_Price_Point','Housing_Prices_Quarter']\n",
    "\n",
    "label_col = ['Income_Adjusted_FMR0']\n",
    "\n",
    "cols_to_think_about = ['State','Year','County','Is_FMR0_Affordable','Is_Rent_Affordable']\n",
    "\n",
    "y_df = df[possible_labels]\n",
    "X_df = df[cols_to_scale + cols_to_onehot]\n",
    "\n",
    "print('number of continuous features: ' + str(len(cols_to_scale)))\n",
    "print('number of categorical features: ' + str(len(cols_to_onehot)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class ExtractColumns(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self,X,y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):\n",
    "        return X[self.attribute_names].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_train_test_split(X,y,test_size = .2):\n",
    "    tot_size = len(X)\n",
    "    test_size = int(tot_size * test_size)\n",
    "    \n",
    "\n",
    "    test_indx = random.sample(range(tot_size),test_size)\n",
    "    train_indx = np.setdiff1d(range(tot_size),test_indx)\n",
    "   \n",
    "    X_train = X.iloc[train_indx,:]\n",
    "    X_test = X.iloc[test_indx,:]\n",
    "   \n",
    "    y_train = y.iloc[train_indx,:]\n",
    "    y_test = y.iloc[test_indx,:]\n",
    "    \n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pipeline = Pipeline([\n",
    "    ('get_cols',ExtractColumns(label_col)),\n",
    "    ('minmaxer',MinMaxScaler())\n",
    "])\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('get_cols',ExtractColumns(cols_to_scale)),\n",
    "    ('scaler',StandardScaler())\n",
    "])\n",
    "cat_pipeline = Pipeline([\n",
    "    ('get_cols',ExtractColumns(cols_to_onehot)),\n",
    "    ('onehot',OneHotEncoder())\n",
    "])\n",
    "\n",
    "my_pipeline = ColumnTransformer([\n",
    "    ('numerical',num_pipeline,cols_to_scale),\n",
    "    ('categorical',cat_pipeline,cols_to_onehot),\n",
    "    ('poly',PolynomialFeatures(degree=2),cols_to_onehot + cols_to_scale)\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = my_train_test_split(X_df,y_df,test_size = .3) #70% training\n",
    "X_val, X_test, y_val,y_test = my_train_test_split(X_test,y_test,test_size = .5) #15% validation\n",
    "\n",
    "y_train = label_pipeline.fit_transform(y_train) #only fit the scaling to the test dataset\n",
    "X_train = my_pipeline.fit_transform(X_train)\n",
    "\n",
    "y_test = label_pipeline.transform(y_test) #transform but don't fit the scaling to the test/validation dataset\n",
    "X_test = my_pipeline.transform(X_test)\n",
    "y_val = label_pipeline.transform(y_val)\n",
    "X_val = my_pipeline.transform(X_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,X_train,X_test,y_train,y_test):\n",
    "    model.fit(X_train,y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    \n",
    "    score = np.sqrt(mean_squared_error(y_test,pred))\n",
    "    plt.scatter(pred,y_test)\n",
    "    plt.plot([0,pred.max()],[0,pred.max()],color ='red');\n",
    "    plt.title('score: ' + str(score))\n",
    "    \n",
    "    return score,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gerardo\\.virtualenvs\\ds4a\\lib\\site-packages\\sklearn\\ensemble\\_voting.py:528: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Voting] ............ (1 of 4) Processing random_forest, total= 4.9min\n"
     ]
    }
   ],
   "source": [
    "for_reg = RandomForestRegressor(n_estimators = 500, max_depth = 8,min_samples_split = 16)\n",
    "svr_reg = SVR(kernel='poly',degree=2,C=1E3)\n",
    "sgd_reg = SGDRegressor(penalty= 'elasticnet',l1_ratio = .5,random_state= 42,learning_rate = 'constant',eta0 = 1E-7)\n",
    "ridge_reg = Ridge(alpha = .9)\n",
    "\n",
    "ensemble = VotingRegressor(estimators = [\n",
    "    ('random_forest',for_reg),\n",
    "    ('svr',svr_reg),\n",
    "    ('sgd',sgd_reg),\n",
    "    ('ridge',ridge_reg)\n",
    "], verbose = True)\n",
    "\n",
    "train_model(ensemble,X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f4004d54da683d7824c68a4b45c97877193d154a7e46656bf5d602672d33cf39"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 ('ds4a')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
